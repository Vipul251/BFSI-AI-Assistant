<img width="1457" height="539" alt="image" src="https://github.com/user-attachments/assets/11d40390-68b8-4d64-9a40-3b8d89416068" /># BFSI-AI-Assistant
# ğŸ¦ BFSI Call Center AI Assistant

A lightweight, compliant, and fully local GenAI assistant designed to handle common Banking, Financial Services, and Insurance (BFSI) customer queries with high accuracy and safety.

Built with **Python, Streamlit, Ollama, and TinyLlama (LoRA fine-tuned)**.

---

## ğŸš€ Project Overview

Call centers in BFSI face three major challenges:

* High volume of repetitive queries
* Need for regulatory-compliant responses
* Requirement for low-latency local solutions

This project solves the problem using a **multiâ€‘tier intelligent pipeline** that prioritizes deterministic answers before using generation.

### ğŸ¯ Supported Query Types

* Loan eligibility & application status
* EMI details & schedules
* Interest rate information
* Payment & transaction queries
* Basic account support

---

## ğŸ§  System Architecture

```
User Query
   â†“
Similarity Search (Alpaca Dataset)
   â†“ (if weak match)
Fineâ€‘Tuned TinyLlama (Local SLM)
   â†“ (if complex)
RAG Knowledge Retrieval
   â†“
Guardrails & Compliance Filter
   â†“
Final Response
```

### âœ… Response Priority

1. **Tier 1 â€” Dataset Match (Highest Priority)**
2. **Tier 2 â€” Fineâ€‘Tuned SLM**
3. **Tier 3 â€” RAG Retrieval**

This ensures **safety first, generation second**.

---

## ğŸ§© Tech Stack

| Layer        | Technology            |
| ------------ | --------------------- |
| UI           | Streamlit             |
| Backend      | Python                |
| Local LLM    | Ollama (TinyLlama)    |
| Fineâ€‘Tuning  | PEFT LoRA             |
| Similarity   | Sentence Transformers |
| Vector Store | FAISS                 |
| Retrieval    | Custom RAG Pipeline   |
| Safety       | Ruleâ€‘based Guardrails |

---
<img width="1457" height="539" alt="image" src="https://github.com/user-attachments/assets/6b713b1d-697c-4285-9e39-6a32baf3bc11" />

## ğŸ“ Project Structure

```
bfsi-assistant/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ alpaca_bfsi.json        # BFSI conversation dataset
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ guardrails.py           # Safety & compliance checks
â”‚   â”œâ”€â”€ ollama_client.py        # Local LLM interface
â”‚   â”œâ”€â”€ rag_pipeline.py         # Knowledge retrieval logic
â”‚   â””â”€â”€ similarity.py           # Dataset similarity matching
â”‚
â”œâ”€â”€ app.py                      # Streamlit UI entry point
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone <your-repo-url>
cd bfsi-assistant
```

---

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
venv\\Scripts\\activate   # Windows
source venv/bin/activate    # Mac/Linux
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Install & Start Ollama

Download Ollama and pull TinyLlama:

```bash
ollama pull tinyllama
ollama serve
```

âœ… Verify:

```bash
ollama run tinyllama
```

---

### 5ï¸âƒ£ Run the Application

```bash
streamlit run app.py
```

Open browser â†’ `http://localhost:8501`

---

## ğŸ§ª Example Queries

Try these in the UI:

* "What is my loan application status?"
* "Explain EMI calculation"
* "Why was my payment declined?"
* "What is the current interest rate?"

---

## ğŸ”’ Guardrails & Compliance

The system enforces strict BFSI safety rules:

* âŒ No guessing financial numbers
* âŒ No fake interest rates
* âŒ No exposure of sensitive data
* âŒ Rejects outâ€‘ofâ€‘domain queries
* âœ… Professional banking tone

Implemented in: `src/guardrails.py`

---

## ğŸ§  Fineâ€‘Tuning Approach

Model: **TinyLlamaâ€‘1.1Bâ€‘Chat**

Method:

* Alpacaâ€‘formatted BFSI dataset
* LoRA (PEFT) fineâ€‘tuning
* Quantized local inference via Ollama

### Why LoRA?

* Low VRAM requirement
* Fast training
* Easy adapter loading
* Production friendly

---

## ğŸ“š RAG Knowledge Base

Used for complex financial explanations such as:

* EMI breakdown
* Interest calculations
* Penalty rules
* Policy explanations

Flow:

```
Query â†’ Embedding â†’ FAISS Search â†’ Context â†’ LLM
```
---

## ğŸ“ˆ Scalability Considerations

* Modular pipeline design
* Versionâ€‘controlled dataset
* Swappable local models
* FAISS index persistence ready
* Streamlit can be containerized

---

## ğŸ³ (Optional) Future Improvements

* Docker deployment
* Redis caching
* Async request handling
* Multiâ€‘language support
* Voice integration for call centers

---

## ğŸ‘¨â€ğŸ’» Author

**Vipul Bhatt**

## â­ If This Helped

Give the repo a star and use it in your portfolio or interviews ğŸš€
